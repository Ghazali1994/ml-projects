# Overfitting & Regularization

**Dataset**: California Housing dataset from sklearn  
**Problem**: Predict house prices based on features  
**What is Overfitting**: When a model performs well on training data but poorly on test data  
**Fixes Tried**: Ridge and Lasso regularization  
**Key Result**: Regularization reduced test error and simplified the model

# Decision Tree vs Random Forest (Titanic Dataset)

**Dataset**: Titanic survival data  
**Goal**: Predict if a passenger survived  
**Models**: Decision Tree and Random Forest  
**Key Learning**: Random Forest gave higher accuracy and used multiple features  
**Bonus**: Feature importance showed 'sex' and 'fare' were most important

# CNN Classifier on MNIST

**Dataset**: MNIST handwritten digits (28x28 grayscale images)  
**Goal**: Classify digits 0â€“9 using a Convolutional Neural Network  
**Model**: 2 Conv layers + MaxPooling + Dense  
**Result**: Achieved ~98% test accuracy  
**What I Learned**: CNNs learn image patterns automatically and generalize better than dense-only models


